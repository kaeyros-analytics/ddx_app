#
# db_pwd <- (db_credentials %>%
#                filter(toupper(db_name) == toupper(db_name_mpay)) %>%
#                dplyr::select(db_pwd) %>%
#                collect())$db_pwd
#
#
#
# --------------------------------------
# (04) CONNECTING R TO THE MPAY DATABASE ####
# --------------------------------------
# # Getting the data file directory
# file_path <- paste(path_data, "/", "generated_db.sqlite3", sep = "")
# # # Here we only use the function dbConnect without the parameter dbname, host, username,
# # # password because we have already saved the SQL data into RStudio
# # # creating the connection to the database
# conn <- DBI::dbConnect(RSQLite::SQLite(), file_path)
#
# # # getting list of tables available
# available_tables <- DBI::dbListTables(conn)
#=========================================
# (1) LOADING AND EXPLORING AVAILABLE DATA ####
#=========================================
# --------------------------
# (10) LOADING REQUIRED DATA ####
# --------------------------
#
# tic()
# for(k in 1:length(available_tables)){
#
#     form <- parse(text = paste(available_tables[k]," <- dbReadTable(con, '", available_tables[k], "')", sep=""))
#     eval(form)
#
# }
# for(k in 1:length(available_tables)){
#
# read the data frame from the sql database
# k <- 2
# form <- parse(text = paste(available_tables[k]," <- DBI::dbReadTable(conn, '", available_tables[k], "')", sep=""))
# eval(form)
# #k <- 2
# form <- parse(text = paste("saveRDS(", available_tables[k], ", file = '" , path_data, "/", available_tables[k], ".rds')", sep=""))
# eval(form)
#
# }
# toc()  # 0.22 sec elapsed
# (04) LOADING REQUIRED FACTS DATA
# --------------------------------
file_path <- paste(path_data, "/testdata.rds", sep="")
system.time(df_testdata <-readRDS(file = file_path))
str(df_testdata)
# check of missing values
sapply(df_testdata, function(k) sum(is.na(k)))
# getting number of unique client_id
length(unique(df_testdata$client_id))
# [1] 100 client
# getting number of unique machine_id
length(unique(df_testdata$machine_id ))
# [1] 3 machines
# getting number of unique user_location
length(unique(df_testdata$localization_lat))
# [1] 300 locations
# use parse_time in order to create standard unambigous date format.
df_testdata <- df_testdata %>%
mutate(date = as.Date(date , format = "%Y-%m-%d"))
#df_testdata$lot_health_index1 <- 100*df_testdata$lot_health_index
str(df_testdata)
# subset the data frame to training data and test
df_filter <- df_testdata %>%
filter( client_id == "client_0",
machine_id == "M_001") %>%
dplyr::select(date, lot_health_index, dynamic_price,avg_market_premium_price)
class(df_filter)
df_filter <- df_filter %>%
dplyr::select(lot_health_index, dynamic_price, avg_market_premium_price)
# Relocate before a specific column
df_filter <- df_filter %>% relocate(dynamic_price, .before = lot_health_index)
mts_df_filter <- stats::ts(df_filter,
frequency = 12,
start = c(2001, 1),
end = c(2021, 12))
class(mts_df_filter)
head(mts_df_filter)
str(mts_df_filter)
# Standard exploratory tools
#par(mfrow = c(1,1))
par(mar = c(2.5,2.5,2.5,2.5))
plot(mts_df_filter, main = "Lot Health Index")
# Main packages - problem: both have different functions VAR
## Testing for stationarity
### tseries - standard test adt.test
apply(mts_df_filter, 2, adf.test)
# Alternative: lib fUnitRoots, function
apply(mts_df_filter, 2, adfTest,
lags=0, #maximum number of lags used for error term correction
type="c", #type of unit root regression
title = "ADF Test for mts_df_filter Data") #title of the project
# Differencing the whole mts
stnry1 <- diffM(mts_df_filter) #difference operation on a vector of time series. Default order of differencing is 1.
# Retest
apply(stnry1, 2, adf.test)
## VAR modeling
plot.ts(stnry1)
# Lag order identification
#We will use two different functions, from two different packages to identify the lag order for the VAR model. Both functions are quite similar to each other but differ in the output they produce. vars::VAR is a more powerful and convinient function to identify the correct lag order.
VARselect(stnry1,
type = "none", #type of deterministic regressors to include. We use none becasue the time series was made stationary using differencing above.
lag.max = 10) #highest lag order
# Lag order identification
#We will use two different functions, from two different packages to identify the lag order for the VAR model. Both functions are quite similar to each other but differ in the output they produce. vars::VAR is a more powerful and convinient function to identify the correct lag order.
VARselect(log1p(mts_df_filter),
type = "none", #type of deterministic regressors to include. We use none becasue the time series was made stationary using differencing above.
lag.max = 10) #highest lag order
# Creating a VAR model with vars
var.a.mts_df_filter <- vars::VAR(stnry1,
lag.max = 10, #highest lag order for lag length selection according to the choosen ic
ic = "AIC", #information criterion
type = "none") #type of deterministic regressors to include
var.a.mts_df_filter
# Creating a VAR model with vars
var.a.mts_df_filter <- vars::VAR(log1p(mts_df_filter),
lag.max = 1, #highest lag order for lag length selection according to the choosen ic
ic = "AIC", #information criterion
type = "none") #type of deterministic regressors to include
var.a.mts_df_filter
# we forecast over a short horizon because beyond short horizon prediction becomes unreliable or uniform
fcast1 = stats::predict(var.a.mts_df_filter, n.ahead = 100)
#par(mfrow = c(0,0))
par(mar = c(2.5,2.5,2.5,2.5))
#par(mfrow = c(2, 2))
plot(fcast1)
library("RSQLite")
library(tidyverse)
library(tidymodels)
library(data.table)
library(tidyposterior)
library(tsibble)       # tibble for time series based on tidy principles
library(fable)         # for forecasting based on tidy principles
library(ggfortify)     # for plotting time series
library(forecast)      # for forecast function
library(tseries)
library(chron)
library(lubridate)
library(directlabels)
library(zoo)
library(lmtest)
library(TTR)  #for smoothing the time series
library(MTS)
library(vars)
library(fUnitRoots)
library(lattice)
library(grid)
library(fpp2)
# Constructing path of relevant directories
root <- getwd()
path_data <- paste(root, "/", "input", sep="")
#path_data <- paste(root, "/", "data", sep="")
path_helpers <- paste(root, "/R", sep="")
#path_helpers <- paste(root, "/codes/helpers", sep="")
path_meta <- paste(root, "/", "meta", sep="")
file_path <- paste(path_data, "/testdata.rds", sep="")
system.time(df_testdata <-readRDS(file = file_path))
str(df_testdata)
# use parse_time in order to create standard ambiguous date format.
df_testdata <- df_testdata %>%
mutate(date = as.Date(date , format = "%Y-%m-%d"))
str(df_testdata)
# subset the data frame
df_filter <- df_testdata %>%
filter( client_id == "client_0",
machine_id == "M_001") %>%
dplyr::select(lot_health_index, dynamic_price,avg_market_premium_price) %>%
relocate(dynamic_price, .before = lot_health_index)
class(df_filter)
df_filter2 <- df_filter %>%
dplyr::select(lot_health_index)
# 2. Explorating the time series   ####
#_____________________________
# Converting a data.frame into mts = Multivariate Time Series
mts_df_filter <- stats::ts(df_filter,
frequency = 12,
start = c(2001, 1),
end = c(2021, 12))
class(mts_df_filter)
# [1] "mts"    "ts"     "matrix"
head(mts_df_filter)
str(mts_df_filter)
colnames(mts_df_filter)
# [1] "dynamic_price"            "lot_health_index"         "avg_market_premium_price"
fig1 <- autoplot(mts_df_filter[,"lot_health_index"], colour = "#7879FF") +
ggtitle("") +
xlab("Year") +
ylab("Iot health index") #+
#theme_bw()
plotly::ggplotly(fig1)
fig2 <- autoplot(mts_df_filter[,"dynamic_price"], colour = "#B03F3C") +
ggtitle("") +
xlab("Year") +
ylab("Dynamic price")
plotly::ggplotly(fig2)
fig3 <- autoplot(mts_df_filter[,"avg_market_premium_price"]) +
ggtitle("") +
xlab("Year") +
ylab("Avg market premium price")
plotly::ggplotly(fig3)
# Seasonal Plot
ggseasonplot(mts_df_filter[,"lot_health_index"], year.labels=TRUE, year.labels.left=TRUE) +
ylab("Iot health index") +
ggtitle("Seasonal plot: Iot health index")
# Seasonal Plot
ggseasonplot(mts_df_filter[,"dynamic_price"], year.labels=TRUE, year.labels.left=TRUE) +
ylab("Dynamic price") +
ggtitle("Seasonal plot: Dynamic price")
# Seasonal Plot
ggseasonplot(mts_df_filter[,"avg_market_premium_price"], year.labels=TRUE, year.labels.left=TRUE) +
ylab("Avg market premium pric") +
ggtitle("Seasonal plot: Avg market premium pric")
# Scatterplot matrices
autoplot(mts_df_filter, facets=TRUE) +
ylab("")
GGally::ggpairs(as.data.frame(mts_df_filter))
# lag plots
gglagplot(mts_df_filter[,"lot_health_index"])
# Autocorrelation
ggAcf(mts_df_filter[,"lot_health_index"])
gglagplot(mts_df_filter[,"dynamic_price"])
# Autocorrelation
ggAcf(mts_df_filter[,"dynamic_price"])
gglagplot(mts_df_filter[,"avg_market_premium_price"])
# Autocorrelation
ggAcf(mts_df_filter[,"avg_market_premium_price"])
df_filter2 <- df_filter %>%
dplyr::select(lot_health_index)  %>%
head(240)
str(df_filter2)
# Converting a data.frame into mts = Multivariate Time Series
ausbeer <- ts(df_filter2,
frequency = 12,
start = c(2001, 1))
ausbeer <- ts(df_filter2,
frequency = 12,
start = c(2001, 1),
end = c(2020, 12))
class(ausbeer)
str(ausbeer)
beer2 <- window(ausbeer,start=2010,end=c(2020,12))
class(beer2)
autoplot(beer2)
str(beer2)
forecast::autoplot(beer2) +
forecast::autolayer(meanf(beer2, h=6),
series="Mean", PI=FALSE)
remove.packages("ggfortify")
unins
remove.packages("ggfortify")
remove.packages("forecast")
remove.packages("forecast")
library(forecast)      # for forecast function
forecast::autoplot(beer2) +
forecast::autolayer(meanf(beer2, h=6),
series="Mean", PI=FALSE)
install.packages("fpp2")
# Constructing path of relevant directories
root <- getwd()
path_data <- paste(root, "/", "input", sep="")
#path_data <- paste(root, "/", "data", sep="")
path_helpers <- paste(root, "/R", sep="")
#path_helpers <- paste(root, "/codes/helpers", sep="")
path_meta <- paste(root, "/", "meta", sep="")
file_path <- paste(path_data, "/testdata.rds", sep="")
system.time(df_testdata <-readRDS(file = file_path))
str(df_testdata)
# use parse_time in order to create standard ambiguous date format.
df_testdata <- df_testdata %>%
mutate(date = as.Date(date , format = "%Y-%m-%d"))
str(df_testdata)
# subset the data frame
df_filter <- df_testdata %>%
filter( client_id == "client_0",
machine_id == "M_001") %>%
dplyr::select(lot_health_index, dynamic_price,avg_market_premium_price) %>%
relocate(dynamic_price, .before = lot_health_index)
class(df_filter)
library(dplyr)
# subset the data frame
df_filter <- df_testdata %>%
filter( client_id == "client_0",
machine_id == "M_001") %>%
dplyr::select(lot_health_index, dynamic_price,avg_market_premium_price) %>%
relocate(dynamic_price, .before = lot_health_index)
class(df_filter)
df_filter2 <- df_filter %>%
dplyr::select(lot_health_index)
# Converting a data.frame into mts = Multivariate Time Series
mts_df_filter <- stats::ts(df_filter,
frequency = 12,
start = c(2001, 1),
end = c(2021, 12))
class(mts_df_filter)
head(mts_df_filter)
str(mts_df_filter)
colnames(mts_df_filter)
fig1 <- autoplot(mts_df_filter[,"lot_health_index"], colour = "#7879FF") +
ggtitle("") +
xlab("Year") +
ylab("Iot health index") #+
find_funs("autoplot")
library(sos)
library(pryr)
# extented fucntion
find_funs <- function(f) {
# Returns dataframe with two columns:
# `package_name`: packages(s) which the function is part of (chr)
# `builtin_package`:  whether the package comes with standard R (a 'builtin'  package)
# Arguments:
# f: name of function for which the package(s) are to be identified.
if ("tidyverse" %in% rownames(installed.packages()) == FALSE) {
cat("tidyverse is needed for this fuction. Please install. Stopping")
stop()}
suppressMessages(library(tidyverse))
# search for help in list of installed packages
help_installed <- help.search(paste0("^",f,"$"), agrep = FALSE)
# extract package name from help file
pckg_hits <- help_installed$matches[,"Package"]
if (length(pckg_hits) == 0) pckg_hits <- "No_results_found"
# get list of built-in packages
pckgs <- installed.packages()  %>% as_tibble
pckgs %>%
dplyr::filter(Priority %in% c("base","recommended")) %>%
dplyr::select(Package) %>%
distinct -> builtin_pckgs_df
# check for each element of 'pckg hit' whether its built-in and loaded (via match). Then print results.
results <- data_frame(
package_name = pckg_hits,
builtin_pckage = match(pckg_hits, builtin_pckgs_df$Package, nomatch = 0) > 0,
loaded = match(paste("package:",pckg_hits, sep = ""), search(), nomatch = 0) > 0
)
return(results)
}
find_funs("autoplot")
library(fpp2)
fig1 <- autoplot(mts_df_filter[,"lot_health_index"], colour = "#7879FF") +
ggtitle("") +
xlab("Year") +
ylab("Iot health index") #+
plotly::ggplotly(fig1)
fig2 <- autoplot(mts_df_filter[,"dynamic_price"], colour = "#B03F3C") +
ggtitle("") +
xlab("Year") +
ylab("Dynamic price")
plotly::ggplotly(fig2)
# Seasonal Plot
ggseasonplot(mts_df_filter[,"lot_health_index"], year.labels=TRUE, year.labels.left=TRUE) +
ylab("Iot health index") +
ggtitle("Seasonal plot: Iot health index")
# Seasonal Plot
ggseasonplot(mts_df_filter[,"dynamic_price"], year.labels=TRUE, year.labels.left=TRUE) +
ylab("Dynamic price") +
ggtitle("Seasonal plot: Dynamic price")
# Seasonal Plot
ggseasonplot(mts_df_filter[,"avg_market_premium_price"], year.labels=TRUE, year.labels.left=TRUE) +
ylab("Avg market premium pric") +
ggtitle("Seasonal plot: Avg market premium pric")
fig3 <- autoplot(mts_df_filter[,"avg_market_premium_price"]) +
ggtitle("") +
xlab("Year") +
ylab("Avg market premium price")
plotly::ggplotly(fig3)
# Scatterplot matrices
autoplot(mts_df_filter, facets=TRUE) +
ylab("")
GGally::ggpairs(as.data.frame(mts_df_filter))
# lag plots
gglagplot(mts_df_filter[,"lot_health_index"])
find_funs("gglagplot")
find_funs("ggAcf")
# Autocorrelation
forecast::ggAcf(mts_df_filter[,"lot_health_index"])
forecast::gglagplot(mts_df_filter[,"dynamic_price"])
# Autocorrelation
forecast::ggAcf(mts_df_filter[,"dynamic_price"])
forecast::gglagplot(mts_df_filter[,"avg_market_premium_price"])
# Autocorrelation
forecast::ggAcf(mts_df_filter[,"avg_market_premium_price"])
df_filter2 <- df_filter %>%
dplyr::select(lot_health_index)  %>%
head(240)
str(df_filter2)
find_funs("ts")
# Converting a data.frame into mts = Multivariate Time Series
ausbeer <- stats::ts(df_filter2,
frequency = 12,
start = c(2001, 1))
ausbeer <- stats::ts(df_filter2,
frequency = 12,
start = c(2001, 1),
end = c(2020, 12))
class(ausbeer)
str(ausbeer)
find_funs("window")
beer2 <- stats::window(ausbeer,start=2010,end=c(2020,12))
class(beer2)
find_funs("autoplot")
find_funs("fpp2")
autoplot(beer2)
find_funs("autolayer")
forecast::autoplot(beer2) +
forecast::autolayer(meanf(beer2, h=6),
series="Mean", PI=FALSE)
# Plot some forecasts (h = forecast horizon) for a seasonal time series
forecast::autoplot(beer2) +
forecast::autolayer(meanf(beer2, h=6),
series="Mean", PI=FALSE) +
autolayer(naive(beer2, h=6),
series="Naïve", PI=FALSE) +
autolayer(snaive(beer2, h=6),
series="Seasonal naïve", PI=FALSE) +
ggtitle("Forecasts for quarterly beer production") +
xlab("Year") + ylab("Megalitres") +
guides(colour=guide_legend(title="Forecast"))
find_funs("ggseasonplot")
# Plot some forecasts (h = forecast horizon) for a seasonal time series
fig4 <- forecast::autoplot(beer2) +
forecast::autolayer(meanf(beer2, h=6),
series="Mean", PI=FALSE) +
autolayer(naive(beer2, h=6),
series="Naïve", PI=FALSE) +
autolayer(snaive(beer2, h=6),
series="Seasonal naïve", PI=FALSE) +
ggtitle("Forecasts for quarterly beer production") +
xlab("Year") + ylab("Megalitres") +
guides(colour=guide_legend(title="Forecast"))
plotly::ggplotly(fig4)
# Plot some forecasts (h = forecast horizon) for a seasonal time series
forecast::autoplot(beer2) +
forecast::autolayer(meanf(beer2, h=6),
series="Mean", PI=FALSE) +
autolayer(naive(beer2, h=6),
series="Naïve", PI=FALSE) +
autolayer(snaive(beer2, h=6),
series="Seasonal naïve", PI=FALSE) +
ggtitle("Forecasts for quarterly beer production") +
xlab("Year") + ylab("Megalitres") +
guides(colour=guide_legend(title="Forecast"))
shiny::runApp()
install.packages("fpp2")
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
install.packages("vars")
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
